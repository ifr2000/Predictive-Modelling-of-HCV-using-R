accuracy2 = sum(diag(cm2))/sum(cm2)
print(accuracy2)
# Make predictions on the testing set using the multinomial model
predicted_quality3 = predict(model5, newdata = test)
rocobj4 = roc(test$hcv, as.numeric(predicted_quality),smoothed = TRUE,plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
print.auc=TRUE, show.thres=TRUE)
##############
##############
##############
#define object to plot
rocobj3 = roc(hcv_test$hcv, as.numeric(hcv_pred),smoothed = TRUE,plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
print.auc=TRUE, show.thres=TRUE)
# Make predictions on the testing set using the random forest model
predicted_quality = predict(rf_model, newdata = test)
###########
#define object to plot
rocobj= roc(test$hcv, as.numeric(predicted_quality),smoothed = TRUE,plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
print.auc=TRUE, show.thres=TRUE)
summary(df)
#Reading the dataset.
df = read.csv("C:/stat_new/Final/Blood_Data/hcvdat.csv",header = TRUE)
df$Age <- cut(df$Age, breaks = c(20, 30, 40, 50, 60, 70), labels = c("20-29", "30-39", "40-49", "50-59", "60-69"))
df = df[,-1]
summary(df)
str(df)
table(df$Category)
model = multinom(Category~.,data=train)
#Reading the dataset.
df = read.csv("C:/stat_new/Final/Blood_Data/hcvdat.csv",header = TRUE)
df$Age <- cut(df$Age, breaks = c(20, 30, 40, 50, 60, 70), labels = c("20-29", "30-39", "40-49", "50-59", "60-69"))
df = df[,-1]
summary(df)
str(df)
df$Category = as.factor(df$Category)
unique(df$Category)
df$Sex = as.factor(df$Sex)
table(df$Category)
index = createDataPartition(df$Category, p = 0.8, list = FALSE)
train = df[index, ]
test = df[-index, ]
na.omit(train)
model = multinom(Category~.,data=train)
summary(model)
cm = table(test$Category, model1)
print(cm)
accuracy = sum(diag(cm))/sum(cm)
print(accuracy)
summary(rf_model)
#Variable Importance Plot
importance(rf_model)
varImpPlot(rf_model)
# Make predictions on the testing set using the random forest model
predicted_quality = predict(rf_model, newdata = test)
cm = table(test$hcv, predicted_quality)
print(cm)
accuracy = sum(diag(cm))/sum(cm)
print(accuracy)
# Make predictions on the testing set using the random forest model
predicted_quality = predict(rf_model, newdata = test)
cm = table(test$hcv, predicted_quality)
cm = table(test$hcv, predicted_quality)
df = df[,-1]
index = createDataPartition(df$hcv, p = 0.7, list = FALSE)
train = df[index, ]
test = df[-index, ]
train <- na.omit(train)
rf_model = randomForest(hcv~.,mtry=3, data = train)
df$hcv = ifelse(df$Category == "0=Blood Donor",0,1)
table(df$hcv)
df$hcv = as.factor(df$hcv)
df$hcv = ifelse(df$Category == "0=Blood Donor",0,1)
table(df$hcv)
df$hcv = as.factor(df$hcv)
pairs.panels(df)
View(df)
#Reading the dataset.
df = read.csv("C:/stat_new/Final/Blood_Data/hcvdat.csv",header = TRUE)
df$Age <- cut(df$Age, breaks = c(20, 30, 40, 50, 60, 70), labels = c("20-29", "30-39", "40-49", "50-59", "60-69"))
df = df[,-1]
summary(df)
df$hcv = ifelse(df$Category == "0=Blood Donor",0,1)
table(df$hcv)
df$hcv = as.factor(df$hcv)
pairs.panels(df)
df = df[,-1]
index = createDataPartition(df$hcv, p = 0.7, list = FALSE)
train = df[index, ]
test = df[-index, ]
train <- na.omit(train)
rf_model = randomForest(hcv~.,mtry=3, data = train)
summary(rf_model)
#Variable Importance Plot
importance(rf_model)
varImpPlot(rf_model)
# Make predictions on the testing set using the random forest model
predicted_quality = predict(rf_model, newdata = test)
cm = table(test$hcv, predicted_quality)
print(cm)
accuracy = sum(diag(cm))/sum(cm)
print(accuracy)
###########
#define object to plot
rocobj= roc(test$hcv, as.numeric(predicted_quality),smoothed = TRUE,plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
print.auc=TRUE, show.thres=TRUE)
# Make predictions on the testing set using the random forest model
predicted_quality = predict(rf_model, newdata = test)
cm = table(test$hcv, predicted_quality)
print(cm)
accuracy = sum(diag(cm))/sum(cm)
print(accuracy)
###########
#define object to plot
rocobj= roc(test$hcv, as.numeric(predicted_quality),smoothed = TRUE,plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
print.auc=TRUE, show.thres=TRUE)
###########
#define object to plot
rocobj= roc(test$hcv, as.numeric(predicted_quality),smoothed = TRUE,plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
print.auc=TRUE, show.thres=TRUE)
View(df)
#Reading the dataset.
df = read.csv("C:/stat_new/Final/Blood_Data/hcvdat.csv",header = TRUE)
df$Age <- cut(df$Age, breaks = c(20, 30, 40, 50, 60, 70), labels = c("20-29", "30-39", "40-49", "50-59", "60-69"))
df = df[,-1]
summary(df)
View(df)
df = df[,-1]
index = createDataPartition(df$hcv, p = 0.7, list = FALSE)
train = df[index, ]
test = df[-index, ]
train <- na.omit(train)
rf_model = randomForest(hcv~.,mtry=3, data = train)
#Reading the dataset.
df = read.csv("C:/stat_new/Final/Blood_Data/hcvdat.csv",header = TRUE)
df$Age <- cut(df$Age, breaks = c(20, 30, 40, 50, 60, 70), labels = c("20-29", "30-39", "40-49", "50-59", "60-69"))
df = df[,-1]
summary(df)
str(df)
df$Category = as.factor(df$Category)
unique(df$Category)
df$Sex = as.factor(df$Sex)
table(df$Category)
index = createDataPartition(df$Category, p = 0.8, list = FALSE)
train = df[index, ]
test = df[-index, ]
na.omit(train)
model = multinom(Category~.,data=train)
summary(model)
model1 = predict(model, newdata = test)
model1
cm = table(test$Category, model1)
print(cm)
accuracy = sum(diag(cm))/sum(cm)
print(accuracy)
df$hcv = ifelse(df$Category == "0=Blood Donor",0,1)
table(df$hcv)
df$hcv = as.factor(df$hcv)
pairs.panels(df)
library(randomForest)
library(DMwR2)
library(randomForestExplainer)
df = df[,-1]
index = createDataPartition(df$hcv, p = 0.7, list = FALSE)
train = df[index, ]
test = df[-index, ]
train <- na.omit(train)
rf_model = randomForest(hcv~.,mtry=3, data = train)
summary(rf_model)
#Variable Importance Plot
importance(rf_model)
varImpPlot(rf_model)
# Make predictions on the testing set using the random forest model
predicted_quality = predict(rf_model, newdata = test)
cm = table(test$hcv, predicted_quality)
print(cm)
accuracy = sum(diag(cm))/sum(cm)
print(accuracy)
###########
#define object to plot
rocobj= roc(test$hcv, as.numeric(predicted_quality),smoothed = TRUE,plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
print.auc=TRUE, show.thres=TRUE)
df1 = subset(df,select= -Sex)
trial_sum <- rep(0, 20)
trial_n <- rep(0, 20)
df1 <- na.omit(df1)
str(df1)
# Make sure they match with the column names of df1
colnames(df1)
for (i in 1:100) {
hcv_sample <- sample(1:nrow(df1), size = nrow(df1) * 0.7)
hcv_train <- na.omit(df1[hcv_sample,])
hcv_test <- na.omit(df1[-hcv_sample,])
test_size <- nrow(hcv_test)
for (j in 1:20) {
hcv_pred = knn(hcv_train[,2:11],hcv_test[,2:11],hcv_train$hcv, k = j)
trial_sum[j] = trial_sum[j] + sum(hcv_pred == hcv_test$hcv)
trial_n[j] = trial_n[j] + test_size
}
}
plot(1 - trial_sum / trial_n, type = "l", ylab = "Error Rate", xlab = "K")
which.min(1 - trial_sum / trial_n)
hcv_pred <- knn(train = hcv_train[,2:11], test = hcv_test[,2:11],
cl = hcv_train$hcv, k = 3)
table(hcv_test$hcv,hcv_pred)
# Convert hcv_test$hcv to factor with levels 0 and 1
hcv_test$hcv <- factor(hcv_test$hcv, levels = c(0, 1))
# Convert hcv_pred to factor with levels 0 and 1
hcv_pred <- factor(hcv_pred, levels = c(0, 1))
# Create confusion matrix
confusionMatrix(hcv_test$hcv, hcv_pred)
#define object to plot
rocobj3 = roc(hcv_test$hcv, as.numeric(hcv_pred),smoothed = TRUE,plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
print.auc=TRUE, show.thres=TRUE)
# Create confusion matrix
confusionMatrix(hcv_test$hcv, hcv_pred)
#define object to plot
rocobj3 = roc(hcv_test$hcv, as.numeric(hcv_pred),smoothed = TRUE,plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
print.auc=TRUE, show.thres=TRUE)
model5 = multinom(hcv~.,data=train)
summary(model5)
model6 = predict(model5, newdata = test)
model6
cm2 = table(test$hcv, model6)
print(cm2)
accuracy2 = sum(diag(cm2))/sum(cm2)
print(accuracy2)
# Make predictions on the testing set using the multinomial model
predicted_quality3 = predict(model5, newdata = test)
rocobj4 = roc(test$hcv, as.numeric(predicted_quality),smoothed = TRUE,plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
print.auc=TRUE, show.thres=TRUE)
model5 = multinom(hcv~.,data=train)
summary(model5)
model6 = predict(model5, newdata = test)
model6
cm2 = table(test$hcv, model6)
print(cm2)
accuracy2 = sum(diag(cm2))/sum(cm2)
print(accuracy2)
# Make predictions on the testing set using the multinomial model
predicted_quality3 = predict(model5, newdata = test)
rocobj4 = roc(test$hcv, as.numeric(predicted_quality),smoothed = TRUE,plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
print.auc=TRUE, show.thres=TRUE)
rocobj4 = roc(test$hcv, as.numeric(predicted_quality3),smoothed = TRUE,plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
print.auc=TRUE, show.thres=TRUE)
# Make predictions on the testing set using the multinomial model
predicted_quality3 = predict(model5, newdata = test)
rocobj4 = roc(test$hcv, as.numeric(predicted_quality3),smoothed = TRUE,plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
print.auc=TRUE, show.thres=TRUE)
model5 = multinom(hcv~.,data=train)
summary(model5)
model6 = predict(model5, newdata = test)
model6
cm2 = table(test$hcv, model6)
print(cm2)
accuracy2 = sum(diag(cm2))/sum(cm2)
print(accuracy2)
# Make predictions on the testing set using the multinomial model
predicted_quality3 = predict(model5, newdata = test)
rocobj4 = roc(test$hcv, as.numeric(predicted_quality3),smoothed = TRUE,plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
print.auc=TRUE, show.thres=TRUE)
model5 = multinom(hcv~.,data=train)
summary(model5)
model6 = predict(model5, newdata = test)
model6
cm2 = table(test$hcv, model6)
print(cm2)
accuracy2 = sum(diag(cm2))/sum(cm2)
print(accuracy2)
# Make predictions on the testing set using the multinomial model
predicted_quality3 = predict(model5, newdata = test)
rocobj4 = roc(test$hcv, as.numeric(predicted_quality3),smoothed = TRUE,plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
print.auc=TRUE, show.thres=TRUE)
for (i in 1:100) {
hcv_sample <- sample(1:nrow(df1), size = nrow(df1) * 0.7)
hcv_train <- na.omit(df1[hcv_sample,])
hcv_test <- na.omit(df1[-hcv_sample,])
test_size <- nrow(hcv_test)
for (j in 1:20) {
hcv_pred = knn(hcv_train[,2:11],hcv_test[,2:11],hcv_train$hcv, k = j)
trial_sum[j] = trial_sum[j] + sum(hcv_pred == hcv_test$hcv)
trial_n[j] = trial_n[j] + test_size
}
}
plot(1 - trial_sum / trial_n, type = "l", ylab = "Error Rate", xlab = "K")
which.min(1 - trial_sum / trial_n)
hcv_pred <- knn(train = hcv_train[,2:11], test = hcv_test[,2:11],
cl = hcv_train$hcv, k = 3)
table(hcv_test$hcv,hcv_pred)
# Convert hcv_test$hcv to factor with levels 0 and 1
hcv_test$hcv <- factor(hcv_test$hcv, levels = c(0, 1))
# Convert hcv_pred to factor with levels 0 and 1
hcv_pred <- factor(hcv_pred, levels = c(0, 1))
# Create confusion matrix
confusionMatrix(hcv_test$hcv, hcv_pred)
model5 = multinom(hcv~.,data=train)
summary(model5)
cm2 = table(test$hcv, model6)
print(cm2)
accuracy2 = sum(diag(cm2))/sum(cm2)
print(accuracy2)
library(tidyverse)
library(caret)
library(ggplot2)
library(reshape2)
require(nnet)
require(foreign)
library(rpart)
library(psych)
library(glmnet)
library(class)
library(ROCR)
library(pROC)
set.seed(123)
#Reading the dataset.
df = read.csv("C:/stat_new/Final/Blood_Data/hcvdat.csv",header = TRUE)
df$Age <- cut(df$Age, breaks = c(20, 30, 40, 50, 60, 70), labels = c("20-29", "30-39", "40-49", "50-59", "60-69"))
df = df[,-1]
summary(df)
str(df)
df$Category = as.factor(df$Category)
unique(df$Category)
df$Sex = as.factor(df$Sex)
table(df$Category)
index = createDataPartition(df$Category, p = 0.8, list = FALSE)
train = df[index, ]
test = df[-index, ]
na.omit(train)
model = multinom(Category~.,data=train)
summary(model)
model1 = predict(model, newdata = test)
model1
cm = table(test$Category, model1)
print(cm)
accuracy = sum(diag(cm))/sum(cm)
print(accuracy)
df$hcv = ifelse(df$Category == "0=Blood Donor",0,1)
table(df$hcv)
df$hcv = as.factor(df$hcv)
pairs.panels(df)
library(randomForest)
library(DMwR2)
library(randomForestExplainer)
df = df[,-1]
index = createDataPartition(df$hcv, p = 0.7, list = FALSE)
train = df[index, ]
test = df[-index, ]
train <- na.omit(train)
rf_model = randomForest(hcv~.,mtry=3, data = train)
summary(rf_model)
#Variable Importance Plot
importance(rf_model)
varImpPlot(rf_model)
# Make predictions on the testing set using the random forest model
predicted_quality = predict(rf_model, newdata = test)
cm = table(test$hcv, predicted_quality)
print(cm)
accuracy = sum(diag(cm))/sum(cm)
print(accuracy)
###########
#define object to plot
rocobj= roc(test$hcv, as.numeric(predicted_quality),smoothed = TRUE,plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
print.auc=TRUE, show.thres=TRUE)
df1 = subset(df,select= -Sex)
trial_sum <- rep(0, 20)
trial_n <- rep(0, 20)
df1 <- na.omit(df1)
str(df1)
# Make sure they match with the column names of df1
colnames(df1)
for (i in 1:100) {
hcv_sample <- sample(1:nrow(df1), size = nrow(df1) * 0.7)
hcv_train <- na.omit(df1[hcv_sample,])
hcv_test <- na.omit(df1[-hcv_sample,])
test_size <- nrow(hcv_test)
for (j in 1:20) {
hcv_pred = knn(hcv_train[,2:11],hcv_test[,2:11],hcv_train$hcv, k = j)
trial_sum[j] = trial_sum[j] + sum(hcv_pred == hcv_test$hcv)
trial_n[j] = trial_n[j] + test_size
}
}
plot(1 - trial_sum / trial_n, type = "l", ylab = "Error Rate", xlab = "K")
which.min(1 - trial_sum / trial_n)
hcv_pred <- knn(train = hcv_train[,2:11], test = hcv_test[,2:11],
cl = hcv_train$hcv, k = 3)
table(hcv_test$hcv,hcv_pred)
# Convert hcv_test$hcv to factor with levels 0 and 1
hcv_test$hcv <- factor(hcv_test$hcv, levels = c(0, 1))
# Convert hcv_pred to factor with levels 0 and 1
hcv_pred <- factor(hcv_pred, levels = c(0, 1))
# Create confusion matrix
confusionMatrix(hcv_test$hcv, hcv_pred)
#define object to plot
rocobj3 = roc(hcv_test$hcv, as.numeric(hcv_pred),smoothed = TRUE,plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
print.auc=TRUE, show.thres=TRUE)
model5 = multinom(hcv~.,data=train)
summary(model5)
model6 = predict(model5, newdata = test)
model6
cm2 = table(test$hcv, model6)
print(cm2)
accuracy2 = sum(diag(cm2))/sum(cm2)
print(accuracy2)
# Make predictions on the testing set using the multinom  ial model
predicted_quality3 = predict(model5, newdata = test)
rocobj4 = roc(test$hcv, as.numeric(predicted_quality3),smoothed = TRUE,plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
print.auc=TRUE, show.thres=TRUE)
##############
library(tidyverse)
library(caret)
library(ggplot2)
library(reshape2)
require(nnet)
require(foreign)
library(rpart)
library(psych)
library(glmnet)
library(class)
library(ROCR)
library(pROC)
set.seed(123)
#Reading the dataset.
df = read.csv("C:/stat_new/Final/Blood_Data/hcvdat.csv",header = TRUE)
df$Age <- cut(df$Age, breaks = c(20, 30, 40, 50, 60, 70), labels = c("20-29", "30-39", "40-49", "50-59", "60-69"))
df = df[,-1]
summary(df)
str(df)
df$Category = as.factor(df$Category)
unique(df$Category)
df$Sex = as.factor(df$Sex)
table(df$Category)
index = createDataPartition(df$Category, p = 0.8, list = FALSE)
train = df[index, ]
test = df[-index, ]
na.omit(train)
model = multinom(Category~.,data=train)
summary(model)
model1 = predict(model, newdata = test)
model1
cm = table(test$Category, model1)
print(cm)
accuracy = sum(diag(cm))/sum(cm)
print(accuracy)
df$hcv = ifelse(df$Category == "0=Blood Donor",0,1)
table(df$hcv)
df$hcv = as.factor(df$hcv)
pairs.panels(df)
library(randomForest)
library(DMwR2)
library(randomForestExplainer)
df = df[,-1]
index = createDataPartition(df$hcv, p = 0.7, list = FALSE)
train = df[index, ]
test = df[-index, ]
train <- na.omit(train)
rf_model = randomForest(hcv~.,mtry=3, data = train)
summary(rf_model)
#Variable Importance Plot
importance(rf_model)
varImpPlot(rf_model)
# Make predictions on the testing set using the random forest model
predicted_quality = predict(rf_model, newdata = test)
cm = table(test$hcv, predicted_quality)
print(cm)
accuracy = sum(diag(cm))/sum(cm)
print(accuracy)
###########
#define object to plot
rocobj= roc(test$hcv, as.numeric(predicted_quality),smoothed = TRUE,plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
print.auc=TRUE, show.thres=TRUE)
df1 = subset(df,select= -Sex)
trial_sum <- rep(0, 20)
trial_n <- rep(0, 20)
df1 <- na.omit(df1)
str(df1)
# Make sure they match with the column names of df1
colnames(df1)
for (i in 1:100) {
hcv_sample <- sample(1:nrow(df1), size = nrow(df1) * 0.7)
hcv_train <- na.omit(df1[hcv_sample,])
hcv_test <- na.omit(df1[-hcv_sample,])
test_size <- nrow(hcv_test)
for (j in 1:20) {
hcv_pred = knn(hcv_train[,2:11],hcv_test[,2:11],hcv_train$hcv, k = j)
trial_sum[j] = trial_sum[j] + sum(hcv_pred == hcv_test$hcv)
trial_n[j] = trial_n[j] + test_size
}
}
plot(1 - trial_sum / trial_n, type = "l", ylab = "Error Rate", xlab = "K")
which.min(1 - trial_sum / trial_n)
hcv_pred <- knn(train = hcv_train[,2:11], test = hcv_test[,2:11],
cl = hcv_train$hcv, k = 3)
table(hcv_test$hcv,hcv_pred)
# Convert hcv_test$hcv to factor with levels 0 and 1
hcv_test$hcv <- factor(hcv_test$hcv, levels = c(0, 1))
# Convert hcv_pred to factor with levels 0 and 1
hcv_pred <- factor(hcv_pred, levels = c(0, 1))
# Create confusion matrix
confusionMatrix(hcv_test$hcv, hcv_pred)
#define object to plot
rocobj3 = roc(hcv_test$hcv, as.numeric(hcv_pred),smoothed = TRUE,plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
print.auc=TRUE, show.thres=TRUE)
model5 = multinom(hcv~.,data=train)
summary(model5)
model6 = predict(model5, newdata = test)
model6
cm2 = table(test$hcv, model6)
print(cm2)
accuracy2 = sum(diag(cm2))/sum(cm2)
print(accuracy2)
# Make predictions on the testing set using the multinom  ial model
predicted_quality3 = predict(model5, newdata = test)
rocobj4 = roc(test$hcv, as.numeric(predicted_quality3),smoothed = TRUE,plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
print.auc=TRUE, show.thres=TRUE)
